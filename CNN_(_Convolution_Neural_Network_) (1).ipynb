{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep_PrwkIQsm7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "ODATi2ATQtLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1/255, shear_range=0.2,zoom_range=0.2)\n"
      ],
      "metadata": {
        "id": "R6MbsbQn9L9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Dog&Cat Images', target_size=(64,64), class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZHPp6xw9wUN",
        "outputId": "5e5e569d-188a-4891-ac77-b4405c6c3780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4iiH6eI-sQD",
        "outputId": "69bb8b68-3c2c-4bd2-b6e2-82611ba9b8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Cat Images': 0, 'Dog Images': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/dog and cat images testing', target_size = (64,64),class_mode=('binary'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvpc5eH1-2O6",
        "outputId": "06a911f5-8586-4c65-aedd-3fa5da0f6719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelling - Convolution Neural Network**\n",
        "\n",
        "**Intializing the CNN**"
      ],
      "metadata": {
        "id": "0CtQre_iBLMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "2W7HxpSLBIV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Convolution**"
      ],
      "metadata": {
        "id": "BwuLSAoSBzma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D\n",
        "classifier.add(Conv2D(input_shape = [64,64,3],filters=32, kernel_size=3,activation='relu'))\n"
      ],
      "metadata": {
        "id": "tNrYZeWGBxzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Max pooling**"
      ],
      "metadata": {
        "id": "nzVJ2aBnD23r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import MaxPooling2D\n",
        "MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2obYBcGD148",
        "outputId": "e9bc864e-2f23-467b-ca93-f997bee2c26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7c9569a3ecb0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Flattening**"
      ],
      "metadata": {
        "id": "Iwj6hEsHEVV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Flatten\n",
        "classifier.add(Flatten())"
      ],
      "metadata": {
        "id": "ptah6KuHEUUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Full_Connection**"
      ],
      "metadata": {
        "id": "WL_seNU6Faq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "classifier.add(Dense(units = 128 , activation= 'relu'))\n",
        "\n",
        "classifier.add(Dense(units = 1 , activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "LckSNWApFZsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the CNN Model with train data & Tesing the model with test data**"
      ],
      "metadata": {
        "id": "T7X8o8BcG2RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "2VET45AYG1bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QaTC32KpH35V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(x = training_set, validation_data = test_set,epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDNif6msHSr5",
        "outputId": "7b01e040-f368-4425-ddc7-62033519528e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7092 - accuracy: 0.3571 - val_loss: 3.5377 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 4.0405 - accuracy: 0.5357 - val_loss: 15.5070 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 467ms/step - loss: 18.1216 - accuracy: 0.5000 - val_loss: 12.3241 - val_accuracy: 0.5000\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 14.0710 - accuracy: 0.5000 - val_loss: 3.9384 - val_accuracy: 0.5000\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 3.8905 - accuracy: 0.5000 - val_loss: 5.0468 - val_accuracy: 0.5000\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 5.4187 - accuracy: 0.5000 - val_loss: 8.2588 - val_accuracy: 0.5000\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 452ms/step - loss: 8.9943 - accuracy: 0.5000 - val_loss: 7.5633 - val_accuracy: 0.5000\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 1s 616ms/step - loss: 8.2159 - accuracy: 0.5000 - val_loss: 4.5122 - val_accuracy: 0.5000\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 4.6046 - accuracy: 0.5000 - val_loss: 0.7354 - val_accuracy: 0.6000\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 0.6207 - accuracy: 0.7143 - val_loss: 2.3587 - val_accuracy: 0.5000\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 2.2777 - accuracy: 0.6071 - val_loss: 3.8211 - val_accuracy: 0.5000\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 3.7510 - accuracy: 0.5714 - val_loss: 3.5705 - val_accuracy: 0.5000\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 3.6589 - accuracy: 0.5714 - val_loss: 2.3158 - val_accuracy: 0.5000\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 2.3979 - accuracy: 0.6429 - val_loss: 1.0030 - val_accuracy: 0.7000\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 1.0738 - accuracy: 0.7500 - val_loss: 0.6272 - val_accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c9569a28f10>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evalution**\n",
        "\n",
        "**Making a single prection**"
      ],
      "metadata": {
        "id": "CK2towVKI4qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "lPP_77duI1t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "test_image = Image.open('/content/Cat or Dog.jpg')\n",
        "\n",
        "# Data Preparation\n",
        "test_image = test_image.resize((64,64))\n",
        "test_image = np.array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 1)\n",
        "\n",
        "# Prediction\n",
        "resized_image = np.reshape(test_image, (1, 64, 64, 3))\n",
        "result = classifier.predict(resized_image)\n",
        "\n",
        "# Evalution\n",
        "if result[0][0] == 1:\n",
        "  print('Dog')\n",
        "else:\n",
        "  print('Cat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih8rzOoVJRph",
        "outputId": "3150b9c2-251b-4343-b9e0-701961929b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n",
            "Dog\n"
          ]
        }
      ]
    }
  ]
}